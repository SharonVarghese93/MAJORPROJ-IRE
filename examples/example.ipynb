{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Dense, Input, Embedding, Concatenate,InputSpec, Activation, Lambda\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas\n",
    "import itertools\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definitions here\n",
    "Few custom layers are defined in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_dim = 300,lstm_op_dim=50,vocab_size=4000,embed_dim=300,max_len=1000,coherence_width=50,k=6, start=3, model_type='tensor'):\n",
    "    if (model_type == 'tensor'):\n",
    "        inputs = Input(shape=(max_len,input_dim))\n",
    "        lstm = LSTM(lstm_op_dim, return_sequences = True)(inputs)    \n",
    "        bilinear_products=Neural_Tensor_layer(output_dim=k,input_dim=lstm_op_dim)\n",
    "        pairs = [((start + i * coherence_width) % max_len, (start + i * coherence_width + coherence_width) % max_len) for i in range(int(max_len/coherence_width))]\n",
    "        similarity_pairs = [ (Lambda(lambda t: t[:, p[0], :])(lstm), Lambda(lambda t: t[:, p[1], :])(lstm)) for p in pairs]\n",
    "        sigmoid_layer = Dense(1, activation=\"sigmoid\")\n",
    "        similarities = [sigmoid_layer(bilinear_products([w[0], w[1]])) for w in similarity_pairs]  \n",
    "        tmp = Temporal_Mean_Pooling()(lstm)\n",
    "        simi = Concatenate()([i for i in similarities])\n",
    "        tmp_simi = Concatenate()([tmp,simi])\n",
    "        dense1 = Dense(256,activation='relu')(tmp_simi)\n",
    "        dense2 = Dense(64,activation='relu')(dense1)\n",
    "        out = Dense(1,activation='linear')(dense2)\n",
    "        model = Model(inputs = inputs, outputs = out)\n",
    "    elif(model_type == 'lstm'):\n",
    "        inputs = Input(shape=(max_len,input_dim))\n",
    "        lstm = LSTM(lstm_op_dim, return_sequences = False)(inputs)\n",
    "        op = Dense(1,activation='linear')(lstm)\n",
    "        model = Model(inputs = inputs, outputs = op)            \n",
    "    return model\n",
    "\n",
    "class Temporal_Mean_Pooling(Layer): \n",
    "    def __init__(self, **kwargs):\n",
    "        self.input_spec=InputSpec(ndim=3)\n",
    "        super(Temporal_Mean_Pooling,self).__init__(**kwargs)\n",
    "\n",
    "    def call(self,x):\n",
    "        mask=K.mean(K.ones_like(x),axis=-1)\n",
    "        return K.sum(x,axis=-2)/K.sum(mask,axis=-1,keepdims=True)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[2])\n",
    "    \n",
    "class Neural_Tensor_layer(Layer):\n",
    "    def __init__(self,output_dim,input_dim=None, **kwargs):\n",
    "        self.output_dim=output_dim\n",
    "        self.input_dim=input_dim\n",
    "        if self.input_dim:\n",
    "            kwargs['input_shape']=(self.input_dim,)\n",
    "        super(Neural_Tensor_layer,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        mean=0.0\n",
    "        std=1.0\n",
    "        k=self.output_dim\n",
    "        d=self.input_dim\n",
    "        W=stats.truncnorm.rvs(-2 * std, 2 * std, loc=mean, scale=std, size=(k,d,d))\n",
    "        V=stats.truncnorm.rvs(-2 * std, 2 * std, loc=mean, scale=std, size=(2*d,k))\n",
    "        self.W=K.variable(W)\n",
    "        self.V=K.variable(V)\n",
    "        self.b=K.zeros((self.input_dim,))\n",
    "        self.trainable_weights=[self.W,self.V,self.b]\n",
    "\n",
    "    def call(self,inputs,mask=None):\n",
    "        e1=inputs[0]\n",
    "        e2=inputs[1]\n",
    "        batch_size=K.shape(e1)[0]\n",
    "        k=self.output_dim\n",
    "        feed_forward=K.dot(K.concatenate([e1,e2]),self.V)\n",
    "        bilinear_tensor_products = [ K.sum((e2 * K.dot(e1, self.W[0])) + self.b, axis=1) ]\n",
    "        for i in range(k)[1:]:\t\n",
    "            btp=K.sum((e2*K.dot(e1,self.W[i]))+self.b,axis=1)\n",
    "            bilinear_tensor_products.append(btp)\n",
    "        result=K.tanh(K.reshape(K.concatenate(bilinear_tensor_products,axis=0),(batch_size,k))+feed_forward)\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        batch_size=input_shape[0][0]\n",
    "        return(batch_size,self.output_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "The following functions read the essays from the file and converts them into glove embeddings that can be fed as input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_training_data(train_path,essay_set = 1):\n",
    "    train_path = train_path\n",
    "    training_data = pandas.read_excel(train_path, delimiter='\\t')\n",
    "    resolved_score = training_data[training_data['essay_set'] == essay_set]['domain1_score']\n",
    "    essay_ids = training_data[training_data['essay_set'] == essay_set]['essay_id']\n",
    "    essays = training_data[training_data['essay_set'] == essay_set]['essay']\n",
    "    essay_list = []\n",
    "    for idx, essay in essays.iteritems():\n",
    "        essay_list.append(clean_tokenize(essay))\n",
    "    return essay_list, resolved_score.tolist(), essay_ids.tolist()\n",
    "\n",
    "def clean_tokenize(data):\n",
    "    data = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", data)\n",
    "    data = re.sub(r\"\\'s\", \" \\'s\", data)\n",
    "    data = re.sub(r\"\\'ve\", \" \\'ve\", data)\n",
    "    data = re.sub(r\"n\\'t\", \" n\\'t\", data)\n",
    "    data = re.sub(r\"\\'re\", \" \\'re\", data)\n",
    "    data = re.sub(r\"\\'d\", \" \\'d\", data)\n",
    "    data = re.sub(r\"\\'ll\", \" \\'ll\", data)\n",
    "    data = re.sub(r\",\", \" , \", data)\n",
    "    data = re.sub(r\"!\", \" ! \", data)\n",
    "    data = re.sub(r\"\\(\", \" ( \", data)\n",
    "    data = re.sub(r\"\\)\", \" ) \", data)\n",
    "    data = re.sub(r\"\\?\", \" ? \", data)\n",
    "    data = re.sub(r\"\\s{2,}\", \" \", data)\n",
    "    data = data.lower()\n",
    "    return [x.strip() for x in re.split('(\\W+)?', data) if x.strip()]\n",
    "\n",
    "\n",
    "def score_range(self):\n",
    "    return {\"1\": (2, 12),\"2\": (1, 6),\"3\": (0, 3),\"4\": (0, 3),\"5\": (0, 4),\"6\": (0, 4),\"7\": (0, 30),\"8\": (0, 60)}\n",
    "\n",
    "def normalize_score(self, essay_set_id, score):\n",
    "    lo, hi = self.score_range[str(essay_set_id)]\n",
    "    score = float(score)\n",
    "    return (score - lo) / (hi - lo)\n",
    "\n",
    "\n",
    "def vectorize_data(data, word_idx, sentence_size):\n",
    "    E = []\n",
    "    for essay in data:\n",
    "        ls = max(0, sentence_size - len(essay))\n",
    "        wl = []\n",
    "        for w in essay:\n",
    "            if w in word_idx:\n",
    "                wl.append(word_idx[w])\n",
    "            else:\n",
    "                wl.append(0)\n",
    "        wl += [0]*ls\n",
    "        E.append(wl)\n",
    "    return E\n",
    "\n",
    "def convert_to_vec(vectorized_data, word2vec):\n",
    "    total_vector = []\n",
    "    for essay in vectorized_data:\n",
    "        essay_vector = []\n",
    "        for word in essay:\n",
    "            essay_vector.append((word2vec[word]))\n",
    "        total_vector.append(essay_vector)\n",
    "    return total_vector\n",
    "\n",
    "def convertword2vec(dim=300):\n",
    "    word2vec = []\n",
    "    word_idx = {}\n",
    "    word2vec.append([0]*dim)\n",
    "    count = 1\n",
    "    with open('glove.6B.300d.txt') as f:\n",
    "        for line in f:\n",
    "            l = line.split()\n",
    "            word = l[0]\n",
    "            vector = list(map(float, l[1:]))\n",
    "            word_idx[word] = count\n",
    "            word2vec.append(vector)\n",
    "            count += 1\n",
    "    return word_idx, word2vec\n",
    "word_idx, word2vec = convertword2vec()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following lines are used to call the above preprocessing function specific to some essay set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/re.py:203: FutureWarning: split() requires a non-empty pattern match.\n",
      "  return _compile(pattern, flags).split(string, maxsplit)\n"
     ]
    }
   ],
   "source": [
    "essay_set_id = 5\n",
    "essay_list, resolved_scores, essay_id = load_training_data('training_set_rel3.xlsx',essay_set_id)\n",
    "vocab_size = len(word_idx) + 1\n",
    "max_sent_size = 1000\n",
    "vectorized_data = vectorize_data(essay_list, word_idx, max_sent_size)\n",
    "X = convert_to_vec(vectorized_data, word2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialising the model and Training\n",
    "Create the model with the choice of paramaters for cohernce width, tensor slices, model type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 1000, 300)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 1000, 50)     70200       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "neural__tensor_layer_2 (Neural_ (None, 6)            15650       lambda_41[0][0]                  \n",
      "                                                                 lambda_42[0][0]                  \n",
      "                                                                 lambda_43[0][0]                  \n",
      "                                                                 lambda_44[0][0]                  \n",
      "                                                                 lambda_45[0][0]                  \n",
      "                                                                 lambda_46[0][0]                  \n",
      "                                                                 lambda_47[0][0]                  \n",
      "                                                                 lambda_48[0][0]                  \n",
      "                                                                 lambda_49[0][0]                  \n",
      "                                                                 lambda_50[0][0]                  \n",
      "                                                                 lambda_51[0][0]                  \n",
      "                                                                 lambda_52[0][0]                  \n",
      "                                                                 lambda_53[0][0]                  \n",
      "                                                                 lambda_54[0][0]                  \n",
      "                                                                 lambda_55[0][0]                  \n",
      "                                                                 lambda_56[0][0]                  \n",
      "                                                                 lambda_57[0][0]                  \n",
      "                                                                 lambda_58[0][0]                  \n",
      "                                                                 lambda_59[0][0]                  \n",
      "                                                                 lambda_60[0][0]                  \n",
      "                                                                 lambda_61[0][0]                  \n",
      "                                                                 lambda_62[0][0]                  \n",
      "                                                                 lambda_63[0][0]                  \n",
      "                                                                 lambda_64[0][0]                  \n",
      "                                                                 lambda_65[0][0]                  \n",
      "                                                                 lambda_66[0][0]                  \n",
      "                                                                 lambda_67[0][0]                  \n",
      "                                                                 lambda_68[0][0]                  \n",
      "                                                                 lambda_69[0][0]                  \n",
      "                                                                 lambda_70[0][0]                  \n",
      "                                                                 lambda_71[0][0]                  \n",
      "                                                                 lambda_72[0][0]                  \n",
      "                                                                 lambda_73[0][0]                  \n",
      "                                                                 lambda_74[0][0]                  \n",
      "                                                                 lambda_75[0][0]                  \n",
      "                                                                 lambda_76[0][0]                  \n",
      "                                                                 lambda_77[0][0]                  \n",
      "                                                                 lambda_78[0][0]                  \n",
      "                                                                 lambda_79[0][0]                  \n",
      "                                                                 lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            7           neural__tensor_layer_2[0][0]     \n",
      "                                                                 neural__tensor_layer_2[1][0]     \n",
      "                                                                 neural__tensor_layer_2[2][0]     \n",
      "                                                                 neural__tensor_layer_2[3][0]     \n",
      "                                                                 neural__tensor_layer_2[4][0]     \n",
      "                                                                 neural__tensor_layer_2[5][0]     \n",
      "                                                                 neural__tensor_layer_2[6][0]     \n",
      "                                                                 neural__tensor_layer_2[7][0]     \n",
      "                                                                 neural__tensor_layer_2[8][0]     \n",
      "                                                                 neural__tensor_layer_2[9][0]     \n",
      "                                                                 neural__tensor_layer_2[10][0]    \n",
      "                                                                 neural__tensor_layer_2[11][0]    \n",
      "                                                                 neural__tensor_layer_2[12][0]    \n",
      "                                                                 neural__tensor_layer_2[13][0]    \n",
      "                                                                 neural__tensor_layer_2[14][0]    \n",
      "                                                                 neural__tensor_layer_2[15][0]    \n",
      "                                                                 neural__tensor_layer_2[16][0]    \n",
      "                                                                 neural__tensor_layer_2[17][0]    \n",
      "                                                                 neural__tensor_layer_2[18][0]    \n",
      "                                                                 neural__tensor_layer_2[19][0]    \n",
      "__________________________________________________________________________________________________\n",
      "temporal__mean__pooling_2 (Temp (None, 50)           0           lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 20)           0           dense_5[0][0]                    \n",
      "                                                                 dense_5[1][0]                    \n",
      "                                                                 dense_5[2][0]                    \n",
      "                                                                 dense_5[3][0]                    \n",
      "                                                                 dense_5[4][0]                    \n",
      "                                                                 dense_5[5][0]                    \n",
      "                                                                 dense_5[6][0]                    \n",
      "                                                                 dense_5[7][0]                    \n",
      "                                                                 dense_5[8][0]                    \n",
      "                                                                 dense_5[9][0]                    \n",
      "                                                                 dense_5[10][0]                   \n",
      "                                                                 dense_5[11][0]                   \n",
      "                                                                 dense_5[12][0]                   \n",
      "                                                                 dense_5[13][0]                   \n",
      "                                                                 dense_5[14][0]                   \n",
      "                                                                 dense_5[15][0]                   \n",
      "                                                                 dense_5[16][0]                   \n",
      "                                                                 dense_5[17][0]                   \n",
      "                                                                 dense_5[18][0]                   \n",
      "                                                                 dense_5[19][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 70)           0           temporal__mean__pooling_2[0][0]  \n",
      "                                                                 concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 256)          18176       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64)           16448       dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 1)            65          dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 120,546\n",
      "Trainable params: 120,546\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(k=6, coherence_width=50, model_type='tensor')\n",
    "model.compile(optimizer=Adam(lr=0.001,decay=1e-6),\n",
    "               loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a test-train split and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1263 samples, validate on 542 samples\n",
      "Epoch 1/200\n",
      "1263/1263 [==============================] - 20s 16ms/step - loss: 6.9059 - val_loss: 4.9875\n",
      "Epoch 2/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 4.5491 - val_loss: 2.8979\n",
      "Epoch 3/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 2.5280 - val_loss: 1.2658\n",
      "Epoch 4/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 1.0818 - val_loss: 0.7013\n",
      "Epoch 5/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.8406 - val_loss: 1.1997\n",
      "Epoch 6/200\n",
      "1263/1263 [==============================] - 12s 10ms/step - loss: 1.1781 - val_loss: 1.0099\n",
      "Epoch 7/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.9081 - val_loss: 0.7058\n",
      "Epoch 8/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.6959 - val_loss: 0.6665\n",
      "Epoch 9/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.7011 - val_loss: 0.7049\n",
      "Epoch 10/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.7328 - val_loss: 0.6616\n",
      "Epoch 11/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.6630 - val_loss: 0.5868\n",
      "Epoch 12/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.6011 - val_loss: 0.5674\n",
      "Epoch 13/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.5758 - val_loss: 0.5607\n",
      "Epoch 14/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.5500 - val_loss: 0.5066\n",
      "Epoch 15/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.4966 - val_loss: 0.4551\n",
      "Epoch 16/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.4567 - val_loss: 0.4260\n",
      "Epoch 17/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.4252 - val_loss: 0.3964\n",
      "Epoch 18/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3983 - val_loss: 0.3728\n",
      "Epoch 19/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3792 - val_loss: 0.3536\n",
      "Epoch 20/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3625 - val_loss: 0.3335\n",
      "Epoch 21/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3421 - val_loss: 0.3215\n",
      "Epoch 22/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3397 - val_loss: 0.3133\n",
      "Epoch 23/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3232 - val_loss: 0.3110\n",
      "Epoch 24/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3344 - val_loss: 0.3071\n",
      "Epoch 25/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3341 - val_loss: 0.3068\n",
      "Epoch 26/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3284 - val_loss: 0.3046\n",
      "Epoch 27/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3313 - val_loss: 0.3033\n",
      "Epoch 28/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3262 - val_loss: 0.3025\n",
      "Epoch 29/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3257 - val_loss: 0.3010\n",
      "Epoch 30/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3233 - val_loss: 0.3014\n",
      "Epoch 31/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3182 - val_loss: 0.2999\n",
      "Epoch 32/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3124 - val_loss: 0.2987\n",
      "Epoch 33/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3200 - val_loss: 0.2978\n",
      "Epoch 34/200\n",
      "1263/1263 [==============================] - 12s 10ms/step - loss: 0.3137 - val_loss: 0.2965\n",
      "Epoch 35/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3161 - val_loss: 0.2952\n",
      "Epoch 36/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3120 - val_loss: 0.2927\n",
      "Epoch 37/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3097 - val_loss: 0.2912\n",
      "Epoch 38/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3090 - val_loss: 0.2912\n",
      "Epoch 39/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3087 - val_loss: 0.2883\n",
      "Epoch 40/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3073 - val_loss: 0.2869\n",
      "Epoch 41/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3004 - val_loss: 0.2872\n",
      "Epoch 42/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.3016 - val_loss: 0.2877\n",
      "Epoch 43/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.3011 - val_loss: 0.2849\n",
      "Epoch 44/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2991 - val_loss: 0.2834\n",
      "Epoch 45/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2923 - val_loss: 0.2813\n",
      "Epoch 46/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2881 - val_loss: 0.2795\n",
      "Epoch 47/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2897 - val_loss: 0.2779\n",
      "Epoch 48/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2879 - val_loss: 0.2782\n",
      "Epoch 49/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2799 - val_loss: 0.2772\n",
      "Epoch 50/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2865 - val_loss: 0.2804\n",
      "Epoch 51/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2852 - val_loss: 0.2761\n",
      "Epoch 52/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2764 - val_loss: 0.2759\n",
      "Epoch 53/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2768 - val_loss: 0.2768\n",
      "Epoch 54/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2703 - val_loss: 0.2698\n",
      "Epoch 55/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2691 - val_loss: 0.2658\n",
      "Epoch 56/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2575 - val_loss: 0.2664\n",
      "Epoch 57/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2537 - val_loss: 0.2625\n",
      "Epoch 58/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2519 - val_loss: 0.2647\n",
      "Epoch 59/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2508 - val_loss: 0.2720\n",
      "Epoch 60/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2538 - val_loss: 0.2688\n",
      "Epoch 61/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2512 - val_loss: 0.2651\n",
      "Epoch 62/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2416 - val_loss: 0.2618\n",
      "Epoch 63/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2363 - val_loss: 0.2610\n",
      "Epoch 64/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2383 - val_loss: 0.2592\n",
      "Epoch 65/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2345 - val_loss: 0.2623\n",
      "Epoch 66/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2320 - val_loss: 0.2593\n",
      "Epoch 67/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2333 - val_loss: 0.2695\n",
      "Epoch 68/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2382 - val_loss: 0.2676\n",
      "Epoch 69/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2433 - val_loss: 0.2673\n",
      "Epoch 70/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2301 - val_loss: 0.2619\n",
      "Epoch 71/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2220 - val_loss: 0.2610\n",
      "Epoch 72/200\n",
      "1263/1263 [==============================] - 11s 9ms/step - loss: 0.2218 - val_loss: 0.2600\n",
      "Epoch 73/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2237 - val_loss: 0.2810\n",
      "Epoch 74/200\n",
      "1263/1263 [==============================] - 12s 9ms/step - loss: 0.2303 - val_loss: 0.2724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c713dbac8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, resolved_scores, test_size=0.3, random_state=42)\n",
    "earlystopping = EarlyStopping(monitor=\"val_loss\", patience=10)  \n",
    "model.fit(X_train,y_train,batch_size = 512,epochs = 200,validation_data=(X_test,y_test), callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the outputs for the validation set and get the final QWK score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7955223225157393\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict_on_batch(X_test)\n",
    "y_val=[int(np.round(a)) for a in y_test]\n",
    "y_pred=[int(np.round(a)) for a in predictions]\n",
    "print(cohen_kappa_score(y_val,y_pred,weights='quadratic'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
